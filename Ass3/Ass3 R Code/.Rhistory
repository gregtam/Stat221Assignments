}
lines.risk(data,descent_values,col = colours[task.num])
task.num
colours[task.num]
plot.risk(data,descent_values, col=colours[task.num])
plot.risk(data,descent_values, col="red")
#2b
plot.risk <- function(data, est,col)
{
# est = p x niters
est.bias = apply(est, 2, function(colum)
log10(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
plot(log10(1:length(est.bias)),est.bias, type="l", lty=3,xlim=range(2,5),ylim=range(-4,4),col=col)
}
lines.risk <- function(data, est,col)
{
# est = p x niters
est.bias = apply(est, 2, function(colum)
log10(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
lines(log10(1:length(est.bias)),est.bias, type="l", lty=3,xlim=range(2,5),ylim=range(-4,4),col=col)
}
for(task.num in 1:4)
{
job.id = 22729420
job.id = 22805866
job.id = 22814597
load(paste("2b_job",job.id,"_task",task.num,".rda",sep=""))
colours = rainbow(4)
A = data$A
theta = descent_values
dim.t = length(theta[1,])
excess_risk = sapply(1:dim.t, function(i) theta[,i] %*% A %*% theta[,i])
if(task.num==1)
{
plot.risk(data,descent_values, col=colours[task.num])
}else
{
lines.risk(data,descent_values,col = colours[task.num])
}
}
for(task.num in 1:4)
{
job.id = 22729420
job.id = 22805866
#   job.id = 22814597
load(paste("2b_job",job.id,"_task",task.num,".rda",sep=""))
colours = rainbow(4)
A = data$A
theta = descent_values
dim.t = length(theta[1,])
excess_risk = sapply(1:dim.t, function(i) theta[,i] %*% A %*% theta[,i])
if(task.num==1)
{
plot.risk(data,descent_values, col=colours[task.num])
}else
{
lines.risk(data,descent_values,col = colours[task.num])
}
}
legend("bottomleft", c("sgd","asgd.good","asgd.bad","implicit"),
lwd = rep(2,4), col=c("black","red","blue","maroon"), title = "Legend",cex=0.9)
lwd = rep(2,4), col=colours, title = "Legend",cex=0.7)
legend("bottomleft", c("sgd","asgd.good","asgd.bad","implicit"),
lwd = rep(2,4), col=colours, title = "Legend",cex=0.7)
legend("bottomleft", c("sgd","asgd.good","asgd.bad","implicit"),
lwd = rep(2,4), col=colours, title = "Legend",cex=0.8)
legend("bottomleft", c("sgd","asgd.good","asgd.bad","implicit"),
lwd = rep(2,4), col=colours, title = "Legend",cex=0.9)
for(task.num in 1:4)
{
job.id = 22729420
job.id = 22805866
#   job.id = 22814597
load(paste("2b_job",job.id,"_task",task.num,".rda",sep=""))
colours = rainbow(4)
A = data$A
theta = descent_values
dim.t = length(theta[1,])
excess_risk = sapply(1:dim.t, function(i) theta[,i] %*% A %*% theta[,i])
if(task.num==1)
{
plot.risk(data,descent_values, col=colours[task.num])
}else
{
lines.risk(data,descent_values,col = colours[task.num])
}
}
legend("bottomleft", c("sgd","asgd","implicit","batch"),
lwd = rep(2,4), col=colours, title = "Legend",cex=0.9)
axis(1,0:6,c("10e0","10e1","10e2","10e3","10e4","10e5","10e6"))
axis(2,-6:2,c("10e-6","10e-5","10e-4","10e-3","10e-2","10e-1","10e0","10e1","10e2"))
for(task.num in 1:4)
{
job.id = 22729420
job.id = 22805866
#   job.id = 22814597
load(paste("2b_job",job.id,"_task",task.num,".rda",sep=""))
colours = rainbow(4)
A = data$A
theta = descent_values
dim.t = length(theta[1,])
excess_risk = sapply(1:dim.t, function(i) theta[,i] %*% A %*% theta[,i])
if(task.num==1)
{
plot.risk(data,descent_values, col=colours[task.num])
}else
{
lines.risk(data,descent_values,col = colours[task.num])
}
}
axis(1,0:5,c("10e0","10e1","10e2","10e3","10e4","10e5"))
axis(2,-4:4,c("10e-4","10e-3","10e-2","10e-1","10e0","10e1","10e2","10e3","10e4"))
plot.risk <- function(data, est,col)
{
# est = p x niters
est.bias = apply(est, 2, function(colum)
log10(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
plot(log10(1:length(est.bias)),est.bias, type="l", lty=3,xlim=range(2,5),ylim=range(-4,4),col=col,axes=FALSE)
}
lines.risk <- function(data, est,col)
{
# est = p x niters
est.bias = apply(est, 2, function(colum)
log10(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
lines(log10(1:length(est.bias)),est.bias, type="l", lty=3,xlim=range(2,5),ylim=range(-4,4),col=col)
}
for(task.num in 1:4)
{
job.id = 22729420
job.id = 22805866
#   job.id = 22814597
load(paste("2b_job",job.id,"_task",task.num,".rda",sep=""))
colours = rainbow(4)
A = data$A
theta = descent_values
dim.t = length(theta[1,])
excess_risk = sapply(1:dim.t, function(i) theta[,i] %*% A %*% theta[,i])
if(task.num==1)
{
plot.risk(data,descent_values, col=colours[task.num])
}else
{
lines.risk(data,descent_values,col = colours[task.num])
}
}
legend("bottomleft", c("sgd","asgd","implicit","batch"),
lwd = rep(2,4), col=colours, title = "Legend",cex=0.9)
#x axis
axis(1,0:5,c("10e0","10e1","10e2","10e3","10e4","10e5"))
#y axis
axis(2,-4:4,c("10e-4","10e-3","10e-2","10e-1","10e0","10e1","10e2","10e3","10e4"))
plot.risk <- function(data, est,col)
{
# est = p x niters
est.bias = apply(est, 2, function(colum)
log10(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
plot(log10(1:length(est.bias)),est.bias, type="l", lty=3,xlim=range(2,5),ylim=range(-4,4),col=col,axes=FALSE,xlab = "training size t", ylab="excess risk")
}
lines.risk <- function(data, est,col)
{
# est = p x niters
est.bias = apply(est, 2, function(colum)
log10(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
lines(log10(1:length(est.bias)),est.bias, type="l", lty=3,xlim=range(2,5),ylim=range(-4,4),col=col)
}
for(task.num in 1:4)
{
job.id = 22729420
job.id = 22805866
job.id = 22814597
load(paste("2b_job",job.id,"_task",task.num,".rda",sep=""))
colours = rainbow(4)
A = data$A
theta = descent_values
dim.t = length(theta[1,])
excess_risk = sapply(1:dim.t, function(i) theta[,i] %*% A %*% theta[,i])
if(task.num==1)
{
plot.risk(data,descent_values, col=colours[task.num])
}else
{
lines.risk(data,descent_values,col = colours[task.num])
}
}
legend("bottomleft", c("sgd","asgd","implicit","batch"),
lwd = rep(2,4), col=colours, title = "Legend",cex=0.9)
#x axis
axis(1,0:5,c("10e0","10e1","10e2","10e3","10e4","10e5"))
#y axis
axis(2,-4:4,c("10e-4","10e-3","10e-2","10e-1","10e0","10e1","10e2","10e3","10e4"))
for(task.num in 1:4)
{
job.id = 22729420
job.id = 22805866
#   job.id = 22814597
load(paste("2b_job",job.id,"_task",task.num,".rda",sep=""))
colours = rainbow(4)
A = data$A
theta = descent_values
dim.t = length(theta[1,])
excess_risk = sapply(1:dim.t, function(i) theta[,i] %*% A %*% theta[,i])
if(task.num==1)
{
plot.risk(data,descent_values, col=colours[task.num])
}else
{
lines.risk(data,descent_values,col = colours[task.num])
}
}
legend("bottomleft", c("sgd","asgd","implicit","batch"),
lwd = rep(2,4), col=colours, title = "Legend",cex=0.9)
#x axis
axis(1,0:5,c("10e0","10e1","10e2","10e3","10e4","10e5"))
#y axis
axis(2,-4:4,c("10e-4","10e-3","10e-2","10e-1","10e0","10e1","10e2","10e3","10e4"))
ls()
job.id = 22853657
for(task.num in 1:6)
{
load(paste("3c_job",job.id,"_task",task.num,".rda",sep=""))
}
rm(list = ls())
job.id = 22853657
for(task.num in 1:6)
{
load(paste("3c_job",job.id,"_task",task.num,".rda",sep=""))
}
ls()
N
p
total_time
times
timesmat = matrix(,nrow=0,ncol=6)
job.id = 22853657
for(task.num in 1:6)
{
load(paste("3c_job",job.id,"_task",task.num,".rda",sep=""))
timesmat = rbind(timesmat,times)
}
timesmat
task.num=1
load(paste("3c_job",job.id,"_task",task.num,".rda",sep=""))
n
P
N
p
task.num=2
load(paste("3c_job",job.id,"_task",task.num,".rda",sep=""))
N
p
timesmat
job.id = 22738468
bias_mat_sgd = matrix(,nrow=0,ncol=10000)
var_mat_sgd = matrix(,nrow=0,ncol=10000)
for(task.num in 1:10)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_sgd = rbind(bias_mat_sgd, biases)
var_mat_sgd = rbind(var_mat_sgd,variances)
}
bias_mat_asgd = matrix(,nrow=0,ncol=10000)
var_mat_asgd = matrix(,nrow=0,ncol=10000)
for(task.num in 11:20)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_asgd = rbind(bias_mat_asgd, biases)
var_mat_asgd = rbind(var_mat_asgd,variances)
}
bias_mat_implicit = matrix(,nrow=0,ncol=10000)
var_mat_implicit = matrix(,nrow=0,ncol=10000)
for(task.num in 21:30)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_implicit = rbind(bias_mat_implicit, biases)
var_mat_implicit = rbind(var_mat_implicit,variances)
}
ls()
rm(list = ls())
job.id = 22738468
bias_mat_sgd = matrix(,nrow=0,ncol=10000)
var_mat_sgd = matrix(,nrow=0,ncol=10000)
for(task.num in 1:10)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_sgd = rbind(bias_mat_sgd, biases)
var_mat_sgd = rbind(var_mat_sgd,variances)
}
bias_mat_asgd = matrix(,nrow=0,ncol=10000)
var_mat_asgd = matrix(,nrow=0,ncol=10000)
for(task.num in 11:20)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_asgd = rbind(bias_mat_asgd, biases)
var_mat_asgd = rbind(var_mat_asgd,variances)
}
bias_mat_implicit = matrix(,nrow=0,ncol=10000)
var_mat_implicit = matrix(,nrow=0,ncol=10000)
for(task.num in 21:30)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_implicit = rbind(bias_mat_implicit, biases)
var_mat_implicit = rbind(var_mat_implicit,variances)
}
ls()
theta
variances
ls()
var_mat_asgd
dim(var_mat_sgd)
dim(var_mat_asgd)
plot.risk <- function(data, est,col)
{
# est = p x niters
est.bias = apply(est, 2, function(colum)
log10(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
plot(log10(1:length(est.bias)),est.bias, type="l", lty=3,xlim=range(2,5),ylim=range(-4,4),col=col,axes=FALSE,xlab = "training size t", ylab="excess risk")
}
lines.risk <- function(data, est,col)
{
# est = p x niters
est.bias = apply(est, 2, function(colum)
log10(t(colum-data$theta) %*% data$A %*% (colum-data$theta)))
lines(log10(1:length(est.bias)),est.bias, type="l", lty=3,xlim=range(2,5),ylim=range(-4,4),col=col)
}
for(task.num in 1:4)
{
job.id = 22729420
job.id = 22805866
job.id = 22814597
load(paste("2b_job",job.id,"_task",task.num,".rda",sep=""))
colours = rainbow(4)
A = data$A
theta = descent_values
dim.t = length(theta[1,])
excess_risk = sapply(1:dim.t, function(i) theta[,i] %*% A %*% theta[,i])
if(task.num==1)
{
plot.risk(data,descent_values, col=colours[task.num])
}else
{
lines.risk(data,descent_values,col = colours[task.num])
}
}
legend("bottomleft", c("sgd","asgd","implicit","batch"),
lwd = rep(2,4), col=colours, title = "Legend",cex=0.9)
#x axis
axis(1,0:5,c("10e0","10e1","10e2","10e3","10e4","10e5"))
#y axis
axis(2,-4:4,c("10e-4","10e-3","10e-2","10e-1","10e0","10e1","10e2","10e3","10e4"))
ls()
rm(list = ls())
job.id = 22738468
bias_mat_sgd = matrix(,nrow=0,ncol=10000)
var_mat_sgd = matrix(,nrow=0,ncol=10000)
for(task.num in 1:10)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_sgd = rbind(bias_mat_sgd, biases)
var_mat_sgd = rbind(var_mat_sgd,variances)
}
bias_mat_asgd = matrix(,nrow=0,ncol=10000)
var_mat_asgd = matrix(,nrow=0,ncol=10000)
for(task.num in 11:20)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_asgd = rbind(bias_mat_asgd, biases)
var_mat_asgd = rbind(var_mat_asgd,variances)
}
bias_mat_implicit = matrix(,nrow=0,ncol=10000)
var_mat_implicit = matrix(,nrow=0,ncol=10000)
for(task.num in 21:30)
{
load(paste("2c_job",job.id,"_task",task.num,".rda",sep=""))
bias_mat_implicit = rbind(bias_mat_implicit, biases)
var_mat_implicit = rbind(var_mat_implicit,variances)
}
ls()
dim(bias_mat_implicit)
dim(var_mat_implicit)
biases
variances
total_time
ls()
descent_values = sample.data.sgd(d,alpha=alpha)
descent_values
#SGD
sample.data.sgd <- function(data, alpha, plot=T)
{
# check.data(data)
# Implements implicit
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(0, nrow=p, ncol=1)
# params for the learning rate seq.
# gamma0 = 1 / (sum(seq(0.01, 1, length.out=p)))
trace = sum(diag(data$A))  # NOTE: data snooping.
I = diag(p)
for(i in 1:n)
{
xi = data$X[i, ]
theta.old = theta.sgd[, i]
ai = alpha / (alpha * tr(A) + n)
# make computations easier.
xi.norm = sum(xi^2)
lpred = sum(theta.old * xi)
fi = 1 / (1 + ai * sum(xi^2))
yi = data$Y[i]
# Standard SGD
theta.new = (theta.old - ai * lpred * xi) + ai * yi * xi
theta.sgd = cbind(theta.sgd, theta.new)
}
colnames(theta.sgd)=NULL
return(list(data = data, theta = theta.sgd))
}
descent_values = sample.data.sgd(d,alpha=alpha)
d = sample.data(dim.n=1e4-1, A)
library(mvtnorm)
bias = function(theta)
{
#returns the bias assuming theta.star is a vector of 1s
log(sqrt(sum((theta-1)^2)))
#   sum(abs(theta-1))
}
random.orthogonal <- function(p)
{
# Get an orthogonal matrix.
B = matrix(runif(p^2), nrow=p)
qr.Q(qr(B))
}
generate.A <- function(p)
{
# Create A matrix (variance of the covariates xn)
Q = random.orthogonal(p)
lambdas = seq(0.01, 1, length.out=p)
A = Q %*% diag(lambdas) %*% t(Q)
return(A)
}
lr <- function(alpha, n)
{
## learning rate
alpha / (alpha + n)
}
tr = function(A)
{
sum=0
{
if(nrow(A)!=ncol(A))
stop("Not a square matrix")
else
{
for(i in 1:nrow(A))
sum = sum + A[i,i]
}
}
sum
}
sample.data <- function(dim.n, A, model="gaussian")
{
# Samples the dataset. Returns a list with (Y, X, A ,true theta)
dim.p = nrow(A)
# This call will make the appropriate checks on A.
X = rmvnorm(dim.n, mean=rep(0, dim.p), sigma=A)
theta = matrix(1, ncol=1, nrow=dim.p)
epsilon = rnorm(dim.n, mean=0, sd=1)
# Data generation
y = X %*% theta  + epsilon
return(list(Y=y, X=X, A=A, theta=theta))
}
#SGD
sample.data.sgd <- function(data, alpha, plot=T)
{
# check.data(data)
# Implements implicit
n = nrow(data$X)
p = ncol(data$X)
# matrix of estimates of SGD (p x iters)
theta.sgd = matrix(0, nrow=p, ncol=1)
# params for the learning rate seq.
# gamma0 = 1 / (sum(seq(0.01, 1, length.out=p)))
trace = sum(diag(data$A))  # NOTE: data snooping.
I = diag(p)
for(i in 1:n)
{
xi = data$X[i, ]
theta.old = theta.sgd[, i]
ai = alpha / (alpha * tr(A) + n)
# make computations easier.
xi.norm = sum(xi^2)
lpred = sum(theta.old * xi)
fi = 1 / (1 + ai * sum(xi^2))
yi = data$Y[i]
# Standard SGD
theta.new = (theta.old - ai * lpred * xi) + ai * yi * xi
theta.sgd = cbind(theta.sgd, theta.new)
}
colnames(theta.sgd)=NULL
return(list(data = data, theta = theta.sgd))
}
#ASGD
A = generate.A(p=100)
d = sample.data(dim.n=1e4-1, A)
descent_values = c()
descent_values = sample.data.sgd(d,alpha=alpha)
alpha=1
descent_values = sample.data.sgd(d,alpha=alpha)
descent_values
names(descent_values)
descent_values$theta
dim(descent_values$theta)
var(descent_values$theta)
dim(var(descent_values$theta))
