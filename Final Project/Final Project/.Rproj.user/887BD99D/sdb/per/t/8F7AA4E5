{
    "contents" : "sigma = c(sqrt(10),1)\nsigma.x = sqrt(2)\n\ntheta = matrix(c(0,1),nrow=2,ncol=1)\n# theta = matrix(c(1,-1),nrow=2,ncol=1)\neta = matrix(,nrow=2,ncol=0)\n\nx = 1/2*rnorm(100, mean=theta[1,1], sd=sigma.x) +\n  1/2*rnorm(100, mean=theta[1,1] + theta[2,1], sd = sigma.x)\n\nN=length(x)\nn=1\n\ntime = 1:10000\na = 0.015\nb = 1\ngamma = 0.55\n\n\nepsilon = a*(b+time)^(-gamma)\nepsilon[1]\nepsilon[length(epsilon)]\n\nt=1\nfor(t in 1:10000)\n{\n  #set most recent theta as previous theta\n  theta.old = theta[,ncol(theta)]\n  #gradient of the log of the prior\n  logprior.grad = -theta.old/sigma\n  #gradient of the loglikelihood\n  ll.grad = function(xtemp)\n  {\n    const = 1/(exp(-(xtemp-theta.old[1])^2/(2*sigma.x^2)) +\n         exp(-(xtemp-theta.old[1]-theta.old[2])^2/(2*sigma.x^2)))\n    vec = c()\n    vec[1] = exp(-(xtemp - theta.old[1])^2/(2*sigma.x^2)) * (xtemp - theta.old[1])/sigma.x^2 +\n      exp(-(xtemp - theta.old[1] - theta.old[2])^2/(2*sigma.x^2)) * (xtemp - theta.old[1] - theta.old[2])/sigma.x^2\n    vec[2] = exp(-(xtemp - theta.old[1] - theta.old[2])^2/(2*sigma.x^2)) *\n      (xtemp - theta.old[1] - theta.old[2])/sigma.x^2\n    const*vec\n  }\n\n  eta = cbind(eta,rnorm(2,mean=0,sd=sqrt(epsilon[t])))\n  ll.grad.vec = sapply(x[1:n],ll.grad)\n\n  #proposed update\n  theta.new = theta.old + epsilon[t]/2*(logprior.grad + N/n*apply(ll.grad.vec,1,sum)) + eta[,ncol(eta)]\n  theta = cbind(theta,theta.new)\n  theta.old = theta.new\n}\n\nplot(theta[1,],theta[2,],xlim=range(-1.5,2.5),ylim=range(-3,3))\n\npdf(\"fig1right.pdf\",width=6,height=6)\nplot(theta[1,],theta[2,],xlim=range(-1.5,2.5),ylim=range(-3,3),col=rgb(0,0,0,alpha=0.1),main=\"Estimated Posterior\")\ndev.off()\n\n# plot(c(),xlim=range(-1.5,2.5),ylim=range(-3,3))\n# text(theta[1,],theta[2,],labels=c(1:10000))\n\n\n\n#Contours of Posterior\nlibrary(lattice)\nprior = function(theta1,theta2){dnorm(theta1,mean=0,sd=sigma[1])*dnorm(theta2,mean=0,sd=sigma[2])}\nlikelihood = function(x,theta1,theta2)\n{\n  1/2*dnorm(x,mean=theta1,sd=sigma.x) + 1/2*dnorm(x,mean=theta1+theta2,sd=sigma.x)\n}\nC = 0\nfor(theta1 in seq(-5,5,by=0.25))\n{\n  for(theta2 in seq(-5,5, by=0.25))\n  {\n    total_likelihood = 1\n    for(i in 1:length(x))\n      total_likelihood = total_likelihood * likelihood(x[i],theta1,theta2)\n    C = C + prior(theta1, theta2) * total_likelihood\n  }\n}\nC\nposterior = function(theta1,theta2,x)\n{\n  post = prior(theta1,theta2)\n  for(i in 1:length(x))\n    post = post * likelihood(x[i],theta1,theta2)\n  post/C\n}\n\n#check if constant works\nfinal_likelihood = 0\nposts = c()\nfor(theta1 in seq(-5,5,by=0.25))\n{\n  for(theta2 in seq(-5,5, by=0.25))\n  {\n    final_likelihood = final_likelihood + posterior(theta1, theta2, x)\n    posts = c(posts,posterior(theta1, theta2, x))\n  }\n}\nfinal_likelihood\n\n\n\ntheta1 = seq(-1.5,2.5,0.25)\ntheta2 = seq(-3,3,0.25)\nab.grid = expand.grid(theta1=theta1,theta2=theta2)\nz = matrix(nrow=length(theta1),ncol=length(theta2))\nfor(i in 1:length(theta1))\n  for(j in 1:length(theta2))\n    z[i,j] = posterior(theta1[i],theta2[j],x)\nab.grid$z = c(z)\n\n#Figure 1\npdf(\"fig1left.pdf\",width=6,height=6)\nprint(contourplot(z ~ theta1*theta2, data=ab.grid, cuts=8, labels=FALSE,main=\"Posterior Contours\"))\ndev.off()\n\n#Figure 2\npdf(\"fig2left.pdf\",width=6,height=6)\nplot(epsilon,type='l',log=\"xy\",ylim=range(10e-6,10e0),col=\"red\",xlab=\"iteration\",ylab=\"noise variance\")\nlines(diff(theta[1,]),col=\"blue\")\nlines(diff(theta[2,]),col=\"green\")\nlegend(1,0.0001,c(\"theta1 noise\",\"theta2 noise\",\"injected noise\"),col=c(\"blue\",\"green\",\"red\"),lwd=c(\"2\",\"2\",\"2\"))\ndev.off()\n\n\n\n\n\n\n",
    "created" : 1418167876543.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1624646309",
    "id" : "8F7AA4E5",
    "lastKnownWriteTime" : 1418838002,
    "path" : "~/Documents/School/Harvard/Third Semester/STAT 221/Assignments/Final Project/Final Project/Implementation1.R",
    "project_path" : "Implementation1.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}